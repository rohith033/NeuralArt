{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn5rbEJ+PaMS86j+RpYucG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohith033/NeuralArt/blob/main/styletransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(input image ,output image(first it would be noise) ,style image ) -> loss function =  loss(input,output) + loss(out,style)\n",
        "\n",
        "optimize the output image so grads repured only for output image \n",
        "\n",
        "network arch \n",
        "---\n",
        "vgg 19 without dense layer <br>\n",
        "we woulde be taking intermediate outputs specifiaclly layers before pooling \n",
        "loss will be sum of output of all these layers \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cTlcbmtUnC5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the intermediate outputs will be the layer right after maxpolling they are listed below"
      ],
      "metadata": {
        "id": "Sk4SoQlxuhQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "now run it through the model and grad the weigths"
      ],
      "metadata": {
        "id": "3TjssH7WuVYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing making shapes of image to 150 150 30"
      ],
      "metadata": {
        "id": "D8jVVvL327VB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make class for model"
      ],
      "metadata": {
        "id": "JmH6vdhhbSyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.models import vgg19\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "yCbwP7Zi5csX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class v19(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(v19,self).__init__()\n",
        "    self.model=vgg19(pretrained=True).features\n",
        "    self.outputs = ['0', '5', '10', '19', '28'] \n",
        "  def forward(self,x):\n",
        "    output = []\n",
        "    for itr , layer in self.model._modules.items():\n",
        "      # print(itr)\n",
        "      x  = layer(x)\n",
        "      if itr in self.outputs:\n",
        "        output.append(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "7nD3s8Q3bRK8"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess =  transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "def load(path):\n",
        "  image = Image.open(path)\n",
        "  image = preprocess(image).unsqueeze(0)\n",
        "  return image\n"
      ],
      "metadata": {
        "id": "VrWKoEI-XPFj"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "art = load('./art.png')\n",
        "input = load('./input.png')\n",
        "styled = input.clone().requires_grad_(True)\n",
        "v19=v19().eval()"
      ],
      "metadata": {
        "id": "g8FrBeT97VQl"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "art_weigth = v19(art)\n",
        "input_weigth = v19(input)\n"
      ],
      "metadata": {
        "id": "06Xnc8w67sdm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(art_weigth))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBiG8U4XEE2d",
        "outputId": "3c82a14e-1555-4a8d-f833-426823250f46"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam([styled], lr=0.001)"
      ],
      "metadata": {
        "id": "0L-efaDE9hVK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 1\n",
        "beta = 0.1\n",
        "itr = 300\n"
      ],
      "metadata": {
        "id": "DCXz13fY-WaL"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,itr):\n",
        "  styled_weigth = v19(styled)\n",
        "  input_loss = 0\n",
        "  art_loss = 0\n",
        "  for l1,l2,l3 in zip(input_weigth,art_weigth,styled_weigth):    \n",
        "    input_loss = torch.mean((l1-l3)**2)/(150*150*3)\n",
        "    _, c, h, w = l2.size()\n",
        "    l2 = l2.view(c, h * w)\n",
        "    l3 = l3.view(c, h * w)\n",
        "    art_loss = torch.mean((torch.mm(l2,l2.t())-torch.mm(l3,l3.t()))**2)/(150*150*3)\n",
        "  loss = art_loss * beta + input_loss * alpha\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=True)\n",
        "  optimizer.step()\n",
        "  if(i%30==0):\n",
        "      img = styled.clone().squeeze()\n",
        "      torchvision.utils.save_image(img, 'output-{}.png'.format(i+1))\n"
      ],
      "metadata": {
        "id": "Jj1bcErW-j0Q"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}